<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | Academic</title>
    <link>/categories/deep-learning/</link>
      <atom:link href="/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 23 Oct 2019 21:35:12 +0800</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Deep Learning</title>
      <link>/categories/deep-learning/</link>
    </image>
    
    <item>
      <title>Learning Feature Engineering</title>
      <link>/post/learning-feature-engineering/</link>
      <pubDate>Wed, 23 Oct 2019 21:35:12 +0800</pubDate>
      <guid>/post/learning-feature-engineering/</guid>
      <description>&lt;h2 id=&#34;learning-feature-engineering-for-classification&#34;&gt;Learning Feature Engineering for Classification&lt;/h2&gt;
&lt;h3 id=&#34;the-structure&#34;&gt;The Structure&lt;/h3&gt;
&lt;p&gt;a stack of ﬁxed-size representations of feature values per target class&lt;/p&gt;
&lt;p&gt;passing the $LFE$ classifier requires a a ﬁxed size feature vector representation&lt;/p&gt;
&lt;h3 id=&#34;problem-formulation&#34;&gt;Problem Formulation&lt;/h3&gt;
&lt;p&gt;Consider a dataset $D$, with features, $F$=${f_1,&amp;hellip;,f_n }$&lt;/p&gt;
&lt;p&gt;A target class, ${ \kappa}$&lt;/p&gt;
&lt;p&gt;The transformation set  $T={T_1,&amp;hellip;T_m}$ and a classification task&lt;/p&gt;
&lt;p&gt;A classification task $L$&lt;/p&gt;
&lt;p&gt;The problem is to find $q$ best paradigm for constructing new features such that appending to the $D$ to maximizes the accuracy of $L$&lt;/p&gt;
&lt;p&gt;Each paradigm consists of a candidate transformation $T_c \in T$ of arity $r$ ,an ordered list of features $[ f_i,&amp;hellip;,f_{i+r-1}]$ and a usefulness score.&lt;/p&gt;
&lt;h3 id=&#34;transformation-recommendation&#34;&gt;Transformation Recommendation&lt;/h3&gt;
&lt;p&gt;LFE models the problem of predicting a useful r-ary transformation $T_c \in T_r$($ T_r\ is\ the\ set\ of\ transformation$) for a given list  $[f_1,&amp;hellip;,f_r]$&lt;/p&gt;
&lt;p&gt;The input is a  set of features&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;one vs rest approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each transformation is modelled as a MLP binary classification with real-valued confidence score as output.&lt;/p&gt;
&lt;p&gt;Apply the $|T_r|$ MLP on features, if the confidence score &amp;gt; threshold $\theta$ ,then choose this transformation.&lt;/p&gt;
&lt;p&gt;$$
c = arg\ max_k(R_{[f_1,&amp;hellip;,f_r]})\&lt;br&gt;
f(n)= \begin{cases} T_c, &amp;amp;\text {if $g_c$($R_{f_1,&amp;hellip;f_r}$) }&amp;gt;\theta
\ none,&amp;amp; \text{otherwise} \end{cases}
$$&lt;/p&gt;
&lt;h3 id=&#34;feature-class-representation&#34;&gt;Feature-Class Representation&lt;/h3&gt;
&lt;p&gt;The transformation are used to reveal and improve significance correlation or discriminative information between features and class labels.&lt;/p&gt;
&lt;p&gt;Correlation $\uparrow$ the effect $uparrow$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;work on improving the correlation!&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;LFE represents feature $f$ in a dataset with $k$ classes as follows:&lt;/p&gt;
&lt;p&gt;$$
R_f=[Q_f^{(1)};Q_f^{(2)};&amp;hellip;;Q_f^{(k)};
$$&lt;/p&gt;
&lt;p&gt;$Q_f^{(i)}$ is a fixed-sized representation of values in $f$ that are associate with class$i$  $\to$ $\text {Quatile Sketch Array}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The generation of $Q_f^{(i)}$&lt;/strong&gt; :**&lt;/p&gt;
&lt;p&gt;The high variability in size and range if feature values makes representative learning and PDF learning difficult.&lt;/p&gt;
&lt;p&gt;We consider features as high dimensions. We determine a fixed size to capture correlations between features and classes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous approaches:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use meta-feature(the distribution of feature to transform the original features.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fixed-size sampling of both feature and classes. The samples need to reflect the distribution of features.&lt;/p&gt;
&lt;p&gt;Such stratified sampling is difficult to apply on the multiple features with high correlations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Hashing can be generated for numerical features but the appropriate function the map small range of feature values to the same hash features is difficult to find.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Quantile Sketching Array integrate these ways.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is familiar with histogram.&lt;/p&gt;
&lt;p&gt;Here we use brute-force way to find k-quantile-point.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Concrete production of  Quantile Sketch:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let $\nu_k$ be the bag of values of feature $f$ for training data point with label $c_k$ and $Q_f^{(i)}$ is the quantile sketch of $\nu_k$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Scale values to a predefined range $[lb,wb]$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bucket all values in $\nu_k$ into a set of bins.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For example, we partition $[lb,wb]$ into $r$ disjoint bins of uniform width,supposing width $w=\frac{wb-lb}r$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assume the bins are ${b_0,&amp;hellip;,b_{r-1}}$,$b_j$ ranges from $[lb+j*w,lb+(j+1)*w]$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;function $B(v_l)$ associates the value $v_l$ in $\nu_k$ to the bin $b_j$&lt;/p&gt;
&lt;p&gt;function $P(b_j)$ returns the number of feature values bucketed in $b_j$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally
$$
I(b_j)=\frac{P(b_j)}{\sum_{0\leq m&amp;lt;r}{P(b_m)}}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;
</description>
    </item>
    
  </channel>
</rss>
